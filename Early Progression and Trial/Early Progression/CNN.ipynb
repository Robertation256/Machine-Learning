{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MultiOutputMixin' from 'sklearn.base' (C:\\Users\\yz391\\Anaconda3\\lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-78718aeaf8de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mundersampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\combine\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_docstring\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSubstitution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_neighbors_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_ball_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_kd_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiOutputMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_distances_chunked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'MultiOutputMixin' from 'sklearn.base' (C:\\Users\\yz391\\Anaconda3\\lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"BaseData.csv\")\n",
    "data.head()\n",
    "data[\"month_num\"] = data[\"month_num\"].astype(int)\n",
    "data[\"day\"] = data[\"day\"].astype(int)\n",
    "\n",
    "data.drop([\"Unnamed: 12\"], axis=1)\n",
    "data.head()\n",
    "\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# undersampler = RandomUnderSampler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# delete_target = []\n",
    "# for i in range(len(data)):\n",
    "#     if len(delete_target) > 700:\n",
    "#         break\n",
    "#     if data.iloc[i,0] == 150:\n",
    "#         delete_target.append(i)\n",
    "        \n",
    "# data = data.drop(delete_target)\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do one-hot on company scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000人以上</th>\n",
       "      <th>500-2000人</th>\n",
       "      <th>50-500人</th>\n",
       "      <th>少于50人</th>\n",
       "      <th>未知规模</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2000人以上 500-2000人 50-500人 少于50人 未知规模\n",
       "0       1         0       0     0    0\n",
       "1       0         0       0     1    0\n",
       "2       0         0       0     1    0\n",
       "3       0         1       0     0    0\n",
       "4       0         0       1     0    0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = data[\"scale\"].to_numpy()\n",
    "\n",
    "def map(string, vector):\n",
    "    res = [\"0\" for i in range(len(vector))]\n",
    "    for i in range(len(vector)):\n",
    "        if isinstance(vector[i],tuple):\n",
    "            for sub_label in vector[i]:\n",
    "                if sub_label in string:\n",
    "                    res[i] = \"1\"\n",
    "        elif vector[i] in string:\n",
    "            res[i] = \"1\"\n",
    "            \n",
    "    return res\n",
    "\n",
    "scale_vector = [\"2000人以上\",(\"500-2000人\",\"500—2000人\"),(\"150-500人\",\"50-100人\",\"50-150人\",\"50-200人\"),(\"15-50人\",\"少于50人\"),\"未知规模\"]\n",
    "\n",
    "mapped_scale = []\n",
    "for i in scale:\n",
    "    mapped = map(i,scale_vector)\n",
    "    mapped_scale.append(mapped)\n",
    "    \n",
    "\n",
    "matrix = np.array(mapped_scale)\n",
    "\n",
    "scale_df = pd.DataFrame(data=matrix, columns=[\"2000人以上\",\"500-2000人\",\"50-500人\",\"少于50人\",\"未知规模\"])\n",
    "scale_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Text Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    新媒体运维实习生（线上）\n",
       "2           测试实习生\n",
       "3     国际学校品牌宣传实习生\n",
       "5         医学数据实习生\n",
       "6         猎头顾问管培生\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_desc = data[\"c_desc\"]\n",
    "c_tag = data[\"c_tag\"]\n",
    "name = data[\"name\"]\n",
    "\n",
    "text_df = name\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1180.,    0.,    0.,  921.,    0.,    0., 1170.,    0.,    0.,\n",
       "        1027.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = []\n",
    "max_sal = data['maxsal'].to_numpy()\n",
    "\n",
    "for i in max_sal:\n",
    "    if i in range(0,150):\n",
    "        label.append(1)\n",
    "    elif i in range(150,175):\n",
    "        label.append(2)\n",
    "    \n",
    "    elif i in range(175,250):\n",
    "        label.append(3)\n",
    "   \n",
    "    else:\n",
    "        label.append(4)\n",
    "        \n",
    "y = np.array(label)\n",
    "y.reshape(len(label),1)\n",
    "plt.hist(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do TF-IDF on Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jieba\n",
    "# import re\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# #Split words\n",
    "# des = text_df[\"text\"].to_list()\n",
    "\n",
    "# cutted_des = [list(jieba.cut(re.sub(r\"[0-9\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", sentence))) for sentence in des]\n",
    "# document = [\" \".join(cutted) for cutted in cutted_des]\n",
    "\n",
    "# #Load stop words\n",
    "# with open(\"cn_stopwords.txt\",\"r\",encoding=\"utf-8\") as fp:\n",
    "#     word_list = fp.read().split(\"\\n\")\n",
    "    \n",
    "# extra_wordlist = [\"一代\",\"一名\",\"一所\",\"一批\",\"一支\",\"一款\",\"一直\",\"一种\",\"一级\",\"一群\"]\n",
    "# word_list += extra_wordlist\n",
    "\n",
    "# tfidf_model = TfidfVectorizer(stop_words=word_list, max_df = 0.005, min_df=0.001).fit(document)\n",
    "\n",
    "# matrix = tfidf_model.transform(document).todense()\n",
    "# volcab = tfidf_model.vocabulary_\n",
    "\n",
    "\n",
    "# name_header = [0]*len(volcab)\n",
    "# for name, val in volcab.items():\n",
    "#     name_header[val] = name\n",
    "    \n",
    "    \n",
    "# processed_df=pd.DataFrame(data=matrix, columns = name_header)\n",
    "\n",
    "# print(len(volcab))\n",
    "# print(volcab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [3],\n",
       "       ...,\n",
       "       [2],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_padded_seqs.shape)\n",
    "y_train.reshape(3999,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D,Flatten,Dropout,BatchNormalization,Dense\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    " \n",
    "\n",
    "#Split words\n",
    "text = data[\"name\"].to_list()\n",
    "cutted_text = [list(jieba.cut(re.sub(r\"[0-9\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——！，;:。？、~@#￥%……&*（）]+\", \" \", sentence))) for sentence in text]\n",
    "corpus = []\n",
    "for i in cutted_text:\n",
    "    corpus += i\n",
    "\n",
    "document = [\" \".join(cutted) for cutted in cutted_text]\n",
    "processed_df = pd.DataFrame(data=document, columns = [\"text\"])\n",
    "\n",
    "\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "model = Word2Vec(corpus, size=50, window=5, min_count=5, workers=4)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_df['text'], y, test_size=0.2,random_state=110)\n",
    "# 将每个样本中的每个词转换为数字列表，使用每个词的编号进行编号\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yz391\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3438, 256, 50)\n",
      "(860, 256, 50)\n"
     ]
    }
   ],
   "source": [
    "def transform_to_matrix(x, padding_size=256, vec_size=50):\n",
    "    res = []\n",
    "    for sen in x:\n",
    "        matrix = []\n",
    "        for i in range(padding_size):\n",
    "            try:\n",
    "                matrix.append(model[sen[i]].tolist())\n",
    "            except:\n",
    "                # 这里有两种except情况，\n",
    "                # 1. 这个单词找不到\n",
    "                # 2. sen没那么长\n",
    "                # 不管哪种情况，我们直接贴上全是0的vec\n",
    "                matrix.append([0] * vec_size)\n",
    "        res.append(matrix)\n",
    "    return res\n",
    "\n",
    "\n",
    "X_train = transform_to_matrix(x_train)\n",
    "X_test = transform_to_matrix(x_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# 看看数组的大小\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3438, 256, 50, 1)\n",
      "(860, 256, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],  X_train.shape[1], X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1)\n",
    "#通过print(X_test)观察与前者的区别，就是多了一个括号\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# set parameters:\n",
    "batch_size = 32\n",
    "n_filter = 16\n",
    "filter_length =4\n",
    "nb_epoch = 200\n",
    "n_pool = 2\n",
    "\n",
    "# 新建一个sequential的模型\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(n_filter,filter_length,filter_length,input_shape=(256, 50,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(n_filter,filter_length,filter_length))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# 后面接上一个ANN\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "# compile模型\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 3.3787 - accuracy: 0.2787\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 3.3787 - accuracy: 0.2787\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 3.3787 - accuracy: 0.2787\n",
      "Epoch 4/200\n",
      " 27/108 [======>.......................] - ETA: 0s - loss: 3.2500 - accuracy: 0.2743"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-551b42b224aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch)\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
